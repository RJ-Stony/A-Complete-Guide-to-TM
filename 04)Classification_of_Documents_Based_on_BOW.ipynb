{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOkBGEIyHnTSPHoPnLYEPMN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RJ-Stony/A-Complete-Guide-to-TM/blob/main/04)Classification_of_Documents_Based_on_BOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 20 Newsgroup data preparation and feature extraction"
      ],
      "metadata": {
        "id": "9MyF6CMinBgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking and Detaching Datasets"
      ],
      "metadata": {
        "id": "E5YIWg680QnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Create a list of Topics you want to select from Among 20 topics\n",
        "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "\n",
        "# Get the training dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "# Delete the hint part from the mail content - Classify it purely by the content\n",
        "                                      remove=('headers', 'footers', 'quotes'),\n",
        "                                      categories=categories)\n",
        "\n",
        "# Get the Test dataset\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',\n",
        "                                     remove=('headers', 'footers', 'quotes'),\n",
        "                                     categories=categories)\n",
        "\n",
        "print('# Train set size:', len(newsgroups_train.data))\n",
        "print('# Test set size:', len(newsgroups_test.data))\n",
        "print('# Selected categories:', newsgroups_train.target_names)\n",
        "print('# Train labels:', set(newsgroups_train.target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzS7-fmO0iGN",
        "outputId": "0edc8a99-4161-43f9-db16-5640bd5a34d5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set size: 2034\n",
            "# Test set size: 1353\n",
            "# Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
            "# Train labels: {0, 1, 2, 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# Train set text samples:', newsgroups_train.data[0])\n",
        "print('# Train set label samples:', newsgroups_train.target[0])\n",
        "print('# Test set text samples:', newsgroups_test.data[0])\n",
        "print('# Test set text samples:', newsgroups_test.target[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD761kvD1N0u",
        "outputId": "576d1b33-d36a-4030-c722-a63bd5526ff4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set text samples: Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "# Train set label samples: 1\n",
            "# Test set text samples: TRry the SKywatch project in  Arizona.\n",
            "# Test set text samples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count-Based Feature Extraction"
      ],
      "metadata": {
        "id": "jH3WpVdU4Qzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = newsgroups_train.data     # Train Dataset Documentation\n",
        "y_train = newsgroups_train.target   # Train Dataset Label\n",
        "\n",
        "X_test = newsgroups_test.data       # Test Dataset Documentation\n",
        "y_test = newsgroups_test.target     # Test Dataset Label\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_features=2000, min_df=5, max_df=.5)\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train)    # Transform the Train set\n",
        "print('Train set dimension:', X_train_cv.shape)\n",
        "X_test_cv = cv.transform(X_test)          # Transform the Test set\n",
        "print('Test set dimension:', X_test_cv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ujhoSQ4o4t",
        "outputId": "d46dac4b-9ab0-4c99-f3ff-2072dcc03c3a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set dimension: (2034, 2000)\n",
            "Test set dimension: (1353, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in zip(\n",
        "    cv.get_feature_names_out()[:100], X_train_cv[0].toarray()[0, :100]\n",
        "):\n",
        "  print(word, ':', count, end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W93oSUoZ5ntg",
        "outputId": "a65634e2-e3fc-4b4c-f3dc-4551d38d37e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification of Documents using a Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "Pkke4y2J6VMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Classifier Declaration\n",
        "NB_clf = MultinomialNB()\n",
        "# Train a Classifier using a Train Set\n",
        "NB_clf.fit(X_train_cv, y_train)\n",
        "\n",
        "# Check the Prediction Accuracy for the Train Set\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
        "# Check the Prediction Accuracy for the Test Set\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgolTSo7Vyn",
        "outputId": "97040c2a-2532-4b5f-892e-afeac75f6e25"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.824\n",
            "Test set score: 0.732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# First Document and label in test data:', X_test[0], y_test[0])\n",
        "print('# Second Document and label in test data:', X_test[1], y_test[1])\n",
        "\n",
        "pred = NB_clf.predict(X_test_cv[:2])\n",
        "\n",
        "print('# Predicted labels:', pred)\n",
        "print(\n",
        "    '# Predicted categories:',\n",
        "    newsgroups_train.target_names[pred[0]],\n",
        "    newsgroups_train.target_names[pred[1]]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtRsr_r_E9l-",
        "outputId": "1b9617f7-8a9f-400a-cba7-5a40fed585e3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# First Document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
            "# Second Document and label in test data: The Vatican library recently made a tour of the US.\n",
            " Can anyone help me in finding a FTP site where this collection is \n",
            " available. 1\n",
            "# Predicted labels: [2 1]\n",
            "# Predicted categories: sci.space comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Use the same Argument as CountVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)    # Return train set\n",
        "X_test_tfidf = tfidf.transform(X_test)          # Return test set\n",
        "\n",
        "# A new Classifier is trained using the tfidf train set.\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Check the Prediction Accuracy for the Train Set\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "\n",
        "# Check the Prediction Accuracy for the Test Set\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "05xi3eqxFsz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8203cdec-5cbb-469e-ae28-2e38fde08a43"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.862\n",
            "Test set score: 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top10_features(classifier, vectorizer, categories):\n",
        "  feature_names = np.asarray(vectorizer.get_feature_names_out())\n",
        "  \n",
        "  for i, category in enumerate(categories):\n",
        "    # To sort in Reverse Order, Take a Negative number for the Coefficient and Return 10 values ​​from the front after Sorting.\n",
        "    top10 = np.argsort(-classifier.coef_[i])[:10]\n",
        "    # Outputs Categories and 10 high-impact Traits\n",
        "    print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
        "\n",
        "top10_features(NB_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo9NlmFKJyVY",
        "outputId": "36c89efa-3ff0-4e07-e598-aa7a4ab2665c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
            "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
            "sci.space: space, on, you, be, was, this, as, they, have, are\n",
            "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification Using Logistic Regression"
      ],
      "metadata": {
        "id": "blM7DQVxKq0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Logistic Regression provided by Sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Perform Regression on the Count Vector and Compare it with NB\n",
        "LR_clf = LogisticRegression()   # Classifier Declaration\n",
        "\n",
        "# Train a Classifier Using Train data\n",
        "LR_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediction Accuracy for the Train Set\n",
        "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "\n",
        "# Prediction Accuracy for the Test Set\n",
        "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhNOvsBrQxFP",
        "outputId": "ae42f5a6-38a2-444e-ca78-742b3735f34d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.930\n",
            "Test set score: 0.734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avoid Overfitting Using Ridge Regression"
      ],
      "metadata": {
        "id": "kZwf6I_3RwB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "ridge_clf = RidgeClassifier()   # RidgeClassifier Declaration\n",
        "ridge_clf.fit(X_train_tfidf, y_train)   # Train\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHWMXj8WSCsJ",
        "outputId": "2c493eca-0284-4f95-c8b7-5fb9f307917e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.960\n",
            "Test set score: 0.735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
        "    X_train_tfidf, y_train, test_size=.2, random_state=42)\n",
        "\n",
        "max_score = 0\n",
        "max_alpha = 0\n",
        "for alpha in np.arange(0.1, 10, 0.1):   # Increase alpha by 0.1 from 0.1 to 10\n",
        "  ridge_clf = RidgeClassifier(alpha=alpha)    # RidgeClassifier Declaration\n",
        "  ridge_clf.fit(X_train_ridge, y_train_ridge)   # Train\n",
        "  # Measuring Accuracy on a Validate Dataset\n",
        "  score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
        "  if score > max_score:   # If the Accuracy is greater than the Previous Maximum Accuracy, change the Maximum.\n",
        "    max_score = score\n",
        "    max_alpha = alpha\n",
        "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJZpsrusTva2",
        "outputId": "3800d62c-8ae9-4c15-8a15-dc63bc9f20e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max alpha 1.600 at max validation score 0.826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_clf = RidgeClassifier(alpha=1.6)    # RidgeClassifier Declaration\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DG1jUMzWKce",
        "outputId": "36cd5869-7c1d-44c0-fd3d-97a1b57900f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.948\n",
            "Test set score: 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_features(ridge_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be86kq_vWrHC",
        "outputId": "2d7db1db-aed1-4f45-897a-3f40a0b05da0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
            "comp.graphics: graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
            "sci.space: space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
            "talk.religion.misc: christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection Using Lasso Regression"
      ],
      "metadata": {
        "id": "MuHxPzDvW3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso uses the Same LogisticRegression While Parameterized\n",
        "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
        "\n",
        "lasso_clf.fit(X_train_tfidf, y_train)   # Learning with Train data\n",
        "\n",
        "print('# Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
        "print('# Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "# Print the number of Non-Zero Coefficients\n",
        "print(\n",
        "    '# Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)),\n",
        "    'out of',\n",
        "    X_train_tfidf.shape[1]\n",
        ")"
      ],
      "metadata": {
        "id": "v5XY5lWNXEfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5e67101-f824-4fb3-a755-802ebe639dc1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.819\n",
            "# Test set score: 0.724\n",
            "# Used features count: 437 out of 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_features(lasso_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xgaWhZIZBww",
        "outputId": "59b13c34-50ac-4fdb-ae60-4c36a92e9724"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice\n",
            "comp.graphics: graphics, image, 3d, file, computer, hi, video, files, looking, sphere\n",
            "sci.space: space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar\n",
            "talk.religion.misc: fbi, christian, christians, christ, order, jesus, children, objective, context, blood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Document Classification Methods using Decision Trees, etc."
      ],
      "metadata": {
        "id": "giyZW3UzZSeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=7)\n",
        "tree.fit(X_train_tfidf, y_train)\n",
        "print('# Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
        "print('# Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))\n",
        "\n",
        "forest = RandomForestClassifier(random_state=7)\n",
        "forest.fit(X_train_tfidf, y_train)\n",
        "print('# Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))\n",
        "print('# Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=7)\n",
        "gb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('# Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))\n",
        "print('# Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR55cwBmhWof",
        "outputId": "e7da954d-a7ec-4a2e-93a4-ea517dbfe960"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Decision Tree train set score: 0.977\n",
            "# Decision Tree test set score: 0.536\n",
            "# Random Forest train set score: 0.977\n",
            "# Random Forest test set score: 0.685\n",
            "# Gradient Boosting train set score: 0.933\n",
            "# Gradient Boosting test set score: 0.696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_feature_importances = sorted(\n",
        "    zip(tfidf.get_feature_names_out(), gb.feature_importances_),\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True,\n",
        ")\n",
        "for feature, value in sorted_feature_importances[:40]:\n",
        "  print('%s: %.3f' % (feature, value), end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ONgK0U_i3k5",
        "outputId": "2220be6c-f668-414c-8e4f-d2c16af8212a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, looking: 0.010, christian: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Increase Performance"
      ],
      "metadata": {
        "id": "Le7tEH1wjmhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egAm4ELIkUo3",
        "outputId": "aa363432-d3b0-420a-ade9-df3707224b00"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "RegTok = RegexpTokenizer(\"[\\w']{3,}\")   # Define tokenizer with Regular Expression\n",
        "english_stops = set(stopwords.words('english'))   # Take English Stopwords\n",
        "\n",
        "def tokenizer(text):\n",
        "  tokens = RegTok.tokenize(text.lower())\n",
        "  # Except Stopwords\n",
        "  words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
        "  # Apply Porter stemmer\n",
        "  features = (list(map(lambda token: PorterStemmer().stem(token), words)))\n",
        "  return features\n",
        "\n",
        "# Using the Newly Defined Tokenizer\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=.5)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)    # Return train set\n",
        "X_test_tfidf = tfidf.transform(X_test)          # Return test set\n",
        "\n",
        "# Classifier Training using Tfidf Vector\n",
        "LR_clf = LogisticRegression()   # Classifier Declaration\n",
        "LR_clf.fit(X_train_tfidf, y_train)    # Train a classifier using train data\n",
        "\n",
        "# Prediction accuracy for Train Data\n",
        "print('# Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "# Prediction accuracy for Test Data\n",
        "print('# Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))\n",
        "len(LR_clf.coef_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLlyir0PkBHX",
        "outputId": "a2bc00a8-d01b-477b-ddd8-db26af6c6557"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.930\n",
            "# Test set score: 0.751\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)    # Return train set\n",
        "# Check How many Attributes are Actually used\n",
        "print('# Train set dimension:', X_train_tfidf.shape)\n",
        "\n",
        "X_test_tfidf = tfidf.transform(X_test)    # Return test set\n",
        "print('# Test set dimension:', X_test_tfidf.shape)\n",
        "\n",
        "ridge_clf = RidgeClassifier(alpha=2.4)\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "print('# Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('# Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=.01)     # Classifier Declaration\n",
        "NB_clf.fit(X_train_tfidf, y_train)    # Training Classifier for train set\n",
        "\n",
        "# Check Prediction Accuracy for Train set\n",
        "print('# Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "# Check Prediction Accuracy for Test set\n",
        "print('# Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXlpJOzBkSC4",
        "outputId": "b225c635-f413-423c-b9ca-e5b582bd1102"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set dimension: (2034, 20085)\n",
            "# Test set dimension: (1353, 20085)\n",
            "# Train set score: 0.968\n",
            "# Test set score: 0.768\n",
            "# Train set score: 0.971\n",
            "# Test set score: 0.793\n"
          ]
        }
      ]
    }
  ]
}