{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP6FO5Z8dZWT9e61SNbU2eq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RJ-Stony/A-Complete-Guide-to-TM/blob/main/04)Classification_of_Documents_Based_on_BOW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 20 Newsgroup data preparation and feature extraction"
      ],
      "metadata": {
        "id": "9MyF6CMinBgu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking and Detaching Datasets"
      ],
      "metadata": {
        "id": "E5YIWg680QnM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "# Create a list of Topics you want to select from Among 20 topics\n",
        "categories = ['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
        "\n",
        "# Get the training dataset\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "# Delete the hint part from the mail content - Classify it purely by the content\n",
        "                                      remove=('headers', 'footers', 'quotes'),\n",
        "                                      categories=categories)\n",
        "\n",
        "# Get the Test dataset\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',\n",
        "                                     remove=('headers', 'footers', 'quotes'),\n",
        "                                     categories=categories)\n",
        "\n",
        "print('# Train set size:', len(newsgroups_train.data))\n",
        "print('# Test set size:', len(newsgroups_test.data))\n",
        "print('# Selected categories:', newsgroups_train.target_names)\n",
        "print('# Train labels:', set(newsgroups_train.target))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzS7-fmO0iGN",
        "outputId": "7af3ff74-e714-4b1d-8f0c-391ecb10d431"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set size: 2034\n",
            "# Test set size: 1353\n",
            "# Selected categories: ['alt.atheism', 'comp.graphics', 'sci.space', 'talk.religion.misc']\n",
            "# Train labels: {0, 1, 2, 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# Train set text samples:', newsgroups_train.data[0])\n",
        "print('# Train set label samples:', newsgroups_train.target[0])\n",
        "print('# Test set text samples:', newsgroups_test.data[0])\n",
        "print('# Test set text samples:', newsgroups_test.target[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD761kvD1N0u",
        "outputId": "96ee102c-30dc-471a-8e63-148bf1311764"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set text samples: Hi,\n",
            "\n",
            "I've noticed that if you only save a model (with all your mapping planes\n",
            "positioned carefully) to a .3DS file that when you reload it after restarting\n",
            "3DS, they are given a default position and orientation.  But if you save\n",
            "to a .PRJ file their positions/orientation are preserved.  Does anyone\n",
            "know why this information is not stored in the .3DS file?  Nothing is\n",
            "explicitly said in the manual about saving texture rules in the .PRJ file. \n",
            "I'd like to be able to read the texture rule information, does anyone have \n",
            "the format for the .PRJ file?\n",
            "\n",
            "Is the .CEL file format available from somewhere?\n",
            "\n",
            "Rych\n",
            "# Train set label samples: 1\n",
            "# Test set text samples: TRry the SKywatch project in  Arizona.\n",
            "# Test set text samples: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Count-Based Feature Extraction"
      ],
      "metadata": {
        "id": "jH3WpVdU4Qzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = newsgroups_train.data     # Train Dataset Documentation\n",
        "y_train = newsgroups_train.target   # Train Dataset Label\n",
        "\n",
        "X_test = newsgroups_test.data       # Test Dataset Documentation\n",
        "y_test = newsgroups_test.target     # Test Dataset Label\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "cv = CountVectorizer(max_features=2000, min_df=5, max_df=.5)\n",
        "\n",
        "X_train_cv = cv.fit_transform(X_train)    # Transform the Train set\n",
        "print('Train set dimension:', X_train_cv.shape)\n",
        "X_test_cv = cv.transform(X_test)          # Transform the Test set\n",
        "print('Test set dimension:', X_test_cv.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1ujhoSQ4o4t",
        "outputId": "46e97433-55f3-40bf-beb0-88ffbc971a88"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set dimension: (2034, 2000)\n",
            "Test set dimension: (1353, 2000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word, count in zip(\n",
        "    cv.get_feature_names_out()[:100], X_train_cv[0].toarray()[0, :100]\n",
        "):\n",
        "  print(word, ':', count, end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W93oSUoZ5ntg",
        "outputId": "13ff14c3-c227-418d-d4e1-e9ed3051eafb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "00 : 0, 000 : 0, 01 : 0, 04 : 0, 05 : 0, 10 : 0, 100 : 0, 1000 : 0, 11 : 0, 12 : 0, 128 : 0, 129 : 0, 13 : 0, 130 : 0, 14 : 0, 15 : 0, 16 : 0, 17 : 0, 18 : 0, 19 : 0, 1987 : 0, 1988 : 0, 1989 : 0, 1990 : 0, 1991 : 0, 1992 : 0, 1993 : 0, 20 : 0, 200 : 0, 202 : 0, 21 : 0, 22 : 0, 23 : 0, 24 : 0, 25 : 0, 256 : 0, 26 : 0, 27 : 0, 28 : 0, 2d : 0, 30 : 0, 300 : 0, 31 : 0, 32 : 0, 33 : 0, 34 : 0, 35 : 0, 39 : 0, 3d : 0, 40 : 0, 400 : 0, 42 : 0, 45 : 0, 50 : 0, 500 : 0, 60 : 0, 600 : 0, 65 : 0, 70 : 0, 75 : 0, 80 : 0, 800 : 0, 90 : 0, 900 : 0, 91 : 0, 92 : 0, 93 : 0, 95 : 0, _the : 0, ability : 0, able : 1, abortion : 0, about : 1, above : 0, absolute : 0, absolutely : 0, ac : 0, accept : 0, acceptable : 0, accepted : 0, access : 0, according : 0, account : 0, accurate : 0, across : 0, act : 0, action : 0, actions : 0, active : 0, activities : 0, activity : 0, acts : 0, actual : 0, actually : 0, ad : 0, add : 0, added : 0, addition : 0, additional : 0, address : 0, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification of Documents using a Naive Bayes Classifier"
      ],
      "metadata": {
        "id": "Pkke4y2J6VMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "# Classifier Declaration\n",
        "NB_clf = MultinomialNB()\n",
        "# Train a Classifier using a Train Set\n",
        "NB_clf.fit(X_train_cv, y_train)\n",
        "\n",
        "# Check the Prediction Accuracy for the Train Set\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_cv, y_train)))\n",
        "# Check the Prediction Accuracy for the Test Set\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_cv, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCgolTSo7Vyn",
        "outputId": "0e5ca416-8e6a-40e1-e453-a594315b27e1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.824\n",
            "Test set score: 0.732\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('# First Document and label in test data:', X_test[0], y_test[0])\n",
        "print('# Second Document and label in test data:', X_test[1], y_test[1])\n",
        "\n",
        "pred = NB_clf.predict(X_test_cv[:2])\n",
        "\n",
        "print('# Predicted labels:', pred)\n",
        "print(\n",
        "    '# Predicted categories:',\n",
        "    newsgroups_train.target_names[pred[0]],\n",
        "    newsgroups_train.target_names[pred[1]]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtRsr_r_E9l-",
        "outputId": "3b8802e8-505e-4bdd-e3da-f95695cfe680"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# First Document and label in test data: TRry the SKywatch project in  Arizona. 2\n",
            "# Second Document and label in test data: The Vatican library recently made a tour of the US.\n",
            " Can anyone help me in finding a FTP site where this collection is \n",
            " available. 1\n",
            "# Predicted labels: [2 1]\n",
            "# Predicted categories: sci.space comp.graphics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Use the same Argument as CountVectorizer\n",
        "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)    # Return train set\n",
        "X_test_tfidf = tfidf.transform(X_test)          # Return test set\n",
        "\n",
        "# A new Classifier is trained using the tfidf train set.\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Check the Prediction Accuracy for the Train Set\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "\n",
        "# Check the Prediction Accuracy for the Test Set\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "05xi3eqxFsz3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03227fd5-089a-4cf3-c684-f15d0ce7d8a2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.862\n",
            "Test set score: 0.741\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def top10_features(classifier, vectorizer, categories):\n",
        "  feature_names = np.asarray(vectorizer.get_feature_names_out())\n",
        "  \n",
        "  for i, category in enumerate(categories):\n",
        "    # To sort in Reverse Order, Take a Negative number for the Coefficient and Return 10 values ​​from the front after Sorting.\n",
        "    top10 = np.argsort(-classifier.coef_[i])[:10]\n",
        "    # Outputs Categories and 10 high-impact Traits\n",
        "    print(\"%s: %s\" % (category, \", \".join(feature_names[top10])))\n",
        "\n",
        "top10_features(NB_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo9NlmFKJyVY",
        "outputId": "38e89f46-ef0e-4bc8-9fd3-8caab69a9575"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: you, not, are, be, this, have, as, what, they, if\n",
            "comp.graphics: you, on, graphics, this, have, any, can, or, with, thanks\n",
            "sci.space: space, on, you, be, was, this, as, they, have, are\n",
            "talk.religion.misc: you, not, he, are, as, this, be, god, was, they\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Document Classification Using Logistic Regression"
      ],
      "metadata": {
        "id": "blM7DQVxKq0q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Logistic Regression provided by Sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Perform Regression on the Count Vector and Compare it with NB\n",
        "LR_clf = LogisticRegression()   # Classifier Declaration\n",
        "\n",
        "# Train a Classifier Using Train data\n",
        "LR_clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediction Accuracy for the Train Set\n",
        "print('Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "\n",
        "# Prediction Accuracy for the Test Set\n",
        "print('Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhNOvsBrQxFP",
        "outputId": "017dff58-0626-4555-bc7f-a11ff16559fa"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.930\n",
            "Test set score: 0.734\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Avoid Overfitting Using Ridge Regression"
      ],
      "metadata": {
        "id": "kZwf6I_3RwB6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "\n",
        "ridge_clf = RidgeClassifier()   # RidgeClassifier Declaration\n",
        "ridge_clf.fit(X_train_tfidf, y_train)   # Train\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHWMXj8WSCsJ",
        "outputId": "022454f4-2617-480a-98ab-2f5dc3cde61d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.960\n",
            "Test set score: 0.735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
        "    X_train_tfidf, y_train, test_size=.2, random_state=42)\n",
        "\n",
        "max_score = 0\n",
        "max_alpha = 0\n",
        "for alpha in np.arange(0.1, 10, 0.1):   # Increase alpha by 0.1 from 0.1 to 10\n",
        "  ridge_clf = RidgeClassifier(alpha=alpha)    # RidgeClassifier Declaration\n",
        "  ridge_clf.fit(X_train_ridge, y_train_ridge)   # Train\n",
        "  # Measuring Accuracy on a Validate Dataset\n",
        "  score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
        "  if score > max_score:   # If the Accuracy is greater than the Previous Maximum Accuracy, change the Maximum.\n",
        "    max_score = score\n",
        "    max_alpha = alpha\n",
        "print('Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJZpsrusTva2",
        "outputId": "aae30e8f-c6dd-4bf1-a4e6-9d1fb9ce2572"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max alpha 1.600 at max validation score 0.826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ridge_clf = RidgeClassifier(alpha=1.6)    # RidgeClassifier Declaration\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DG1jUMzWKce",
        "outputId": "81ecb229-dfd0-456c-8500-2751602415e5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.948\n",
            "Test set score: 0.739\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_features(ridge_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be86kq_vWrHC",
        "outputId": "ad0e473a-a9ec-42c2-da1b-eda148d89c9d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: bobby, religion, atheism, atheists, motto, punishment, islam, deletion, islamic, satan\n",
            "comp.graphics: graphics, computer, 3d, file, image, hi, 42, using, screen, looking\n",
            "sci.space: space, orbit, nasa, spacecraft, moon, sci, launch, flight, funding, idea\n",
            "talk.religion.misc: christian, christians, fbi, blood, order, jesus, objective, children, christ, hudson\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Selection Using Lasso Regression"
      ],
      "metadata": {
        "id": "MuHxPzDvW3vv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso uses the Same LogisticRegression While Parameterized\n",
        "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=1)\n",
        "\n",
        "lasso_clf.fit(X_train_tfidf, y_train)   # Learning with Train data\n",
        "\n",
        "print('# Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
        "print('# Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "# Print the number of Non-Zero Coefficients\n",
        "print(\n",
        "    '# Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)),\n",
        "    'out of',\n",
        "    X_train_tfidf.shape[1]\n",
        ")"
      ],
      "metadata": {
        "id": "v5XY5lWNXEfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58fe52e-2526-4908-d988-74c86ece9be1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.819\n",
            "# Test set score: 0.724\n",
            "# Used features count: 437 out of 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top10_features(lasso_clf, tfidf, newsgroups_train.target_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xgaWhZIZBww",
        "outputId": "4ef9e13f-28b3-467f-852d-3da257934d9b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alt.atheism: bobby, atheism, atheists, islam, religion, islamic, motto, atheist, satan, vice\n",
            "comp.graphics: graphics, image, 3d, file, computer, hi, video, files, looking, sphere\n",
            "sci.space: space, orbit, launch, nasa, spacecraft, flight, moon, dc, shuttle, solar\n",
            "talk.religion.misc: fbi, christian, christians, christ, order, jesus, children, objective, context, blood\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other Document Classification Methods using Decision Trees, etc."
      ],
      "metadata": {
        "id": "giyZW3UzZSeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier(random_state=7)\n",
        "tree.fit(X_train_tfidf, y_train)\n",
        "print('# Decision Tree train set score: {:.3f}'.format(tree.score(X_train_tfidf, y_train)))\n",
        "print('# Decision Tree test set score: {:.3f}'.format(tree.score(X_test_tfidf, y_test)))\n",
        "\n",
        "forest = RandomForestClassifier(random_state=7)\n",
        "forest.fit(X_train_tfidf, y_train)\n",
        "print('# Random Forest train set score: {:.3f}'.format(forest.score(X_train_tfidf, y_train)))\n",
        "print('# Random Forest test set score: {:.3f}'.format(forest.score(X_test_tfidf, y_test)))\n",
        "\n",
        "gb = GradientBoostingClassifier(random_state=7)\n",
        "gb.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('# Gradient Boosting train set score: {:.3f}'.format(gb.score(X_train_tfidf, y_train)))\n",
        "print('# Gradient Boosting test set score: {:.3f}'.format(gb.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YR55cwBmhWof",
        "outputId": "1812976e-aae6-4796-ac76-85f9d6c86fc3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Decision Tree train set score: 0.977\n",
            "# Decision Tree test set score: 0.536\n",
            "# Random Forest train set score: 0.977\n",
            "# Random Forest test set score: 0.685\n",
            "# Gradient Boosting train set score: 0.933\n",
            "# Gradient Boosting test set score: 0.696\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_feature_importances = sorted(\n",
        "    zip(tfidf.get_feature_names_out(), gb.feature_importances_),\n",
        "    key=lambda x: x[1],\n",
        "    reverse=True,\n",
        ")\n",
        "for feature, value in sorted_feature_importances[:40]:\n",
        "  print('%s: %.3f' % (feature, value), end=', ')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ONgK0U_i3k5",
        "outputId": "b8a95279-95cb-4c84-a94c-a907692e6098"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "space: 0.126, graphics: 0.080, atheism: 0.024, thanks: 0.023, file: 0.021, orbit: 0.020, jesus: 0.018, god: 0.018, hi: 0.017, nasa: 0.015, image: 0.015, files: 0.014, christ: 0.010, moon: 0.010, bobby: 0.010, launch: 0.010, looking: 0.010, christian: 0.010, atheists: 0.009, christians: 0.009, fbi: 0.009, 3d: 0.008, you: 0.008, not: 0.008, islamic: 0.007, religion: 0.007, spacecraft: 0.007, flight: 0.007, computer: 0.007, islam: 0.007, ftp: 0.006, color: 0.006, software: 0.005, atheist: 0.005, card: 0.005, people: 0.005, koresh: 0.005, his: 0.005, kent: 0.004, sphere: 0.004, "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Increase Performance"
      ],
      "metadata": {
        "id": "Le7tEH1wjmhi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egAm4ELIkUo3",
        "outputId": "821fbf5b-72a8-4848-d57e-a33a7f54cbac"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import re\n",
        "\n",
        "RegTok = RegexpTokenizer(\"[\\w']{3,}\")   # Define tokenizer with Regular Expression\n",
        "english_stops = set(stopwords.words('english'))   # Take English Stopwords\n",
        "\n",
        "def tokenizer(text):\n",
        "  tokens = RegTok.tokenize(text.lower())\n",
        "  # Except Stopwords\n",
        "  words = [word for word in tokens if (word not in english_stops) and len(word) > 2]\n",
        "  # Apply Porter stemmer\n",
        "  features = (list(map(lambda token: PorterStemmer().stem(token), words)))\n",
        "  return features\n",
        "\n",
        "# Using the Newly Defined Tokenizer\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer, max_features=2000, min_df=5, max_df=.5)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)    # Return train set\n",
        "X_test_tfidf = tfidf.transform(X_test)          # Return test set\n",
        "\n",
        "# Classifier Training using Tfidf Vector\n",
        "LR_clf = LogisticRegression()   # Classifier Declaration\n",
        "LR_clf.fit(X_train_tfidf, y_train)    # Train a classifier using train data\n",
        "\n",
        "# Prediction accuracy for Train Data\n",
        "print('# Train set score: {:.3f}'.format(LR_clf.score(X_train_tfidf, y_train)))\n",
        "# Prediction accuracy for Test Data\n",
        "print('# Test set score: {:.3f}'.format(LR_clf.score(X_test_tfidf, y_test)))\n",
        "len(LR_clf.coef_[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mLlyir0PkBHX",
        "outputId": "4deefbf0-3738-41d4-f261-d0c491eb9ab5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.930\n",
            "# Test set score: 0.751\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf = TfidfVectorizer(tokenizer=tokenizer)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)    # Return train set\n",
        "# Check How many Attributes are Actually used\n",
        "print('# Train set dimension:', X_train_tfidf.shape)\n",
        "\n",
        "X_test_tfidf = tfidf.transform(X_test)    # Return test set\n",
        "print('# Test set dimension:', X_test_tfidf.shape)\n",
        "\n",
        "ridge_clf = RidgeClassifier(alpha=2.4)\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "print('# Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('# Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=.01)     # Classifier Declaration\n",
        "NB_clf.fit(X_train_tfidf, y_train)    # Training Classifier for train set\n",
        "\n",
        "# Check Prediction Accuracy for Train set\n",
        "print('# Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "# Check Prediction Accuracy for Test set\n",
        "print('# Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXlpJOzBkSC4",
        "outputId": "418fc19c-5eb3-4a5f-ee10-81f5e033c0a2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set dimension: (2034, 20085)\n",
            "# Test set dimension: (1353, 20085)\n",
            "# Train set score: 0.968\n",
            "# Test set score: 0.768\n",
            "# Train set score: 0.971\n",
            "# Test set score: 0.793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Count-based problem and Complement using N-gram"
      ],
      "metadata": {
        "id": "_DE4YetThD9Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Document Classification using N-gram"
      ],
      "metadata": {
        "id": "8u2ieaJ7hR_M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "cachedStopWords = stopwords.words(\"english\")\n",
        "tfidf = TfidfVectorizer(token_pattern= \"[a-zA-Z']{3,}\",     # Regular Expressions for Tokenization\n",
        "                        decode_error='ignore',\n",
        "                        lowercase=True,\n",
        "                        stop_words=stopwords.words('english'),\n",
        "                        max_df=.5,\n",
        "                        min_df=2)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(X_train_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SgvhIMvdheqW",
        "outputId": "a15ca3f5-2491-4603-fa77-d9c60a58b433"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2034, 11483)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import RidgeClassifier\n",
        "ridge_clf = RidgeClassifier()   # Ridge Classifier Declaration\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qhnfi0ipiIi5",
        "outputId": "106b1c68-8a03-4f27-ac8f-66c70b0a6cd5"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.976\n",
            "Test set score: 0.766\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(token_pattern=\"[a-zA-Z']{3,}\",\n",
        "                        decode_error='ignore',\n",
        "                        lowercase=True,\n",
        "                        stop_words=stopwords.words('english'),\n",
        "                        ngram_range=(1, 2),     # Bi-gram Settings\n",
        "                        max_df=.5,\n",
        "                        min_df=2)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "print(X_train_tfidf.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xc6xeAvjo0f",
        "outputId": "e7c8fe2d-5c6f-4821-e028-f457d21807a2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2034, 26550)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 1]\n",
        "print('bi-gram samples:', bigram_features[:10])\n",
        "\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etX6aXlmkNze",
        "outputId": "378cf83b-5ec5-40f9-da14-77400f3f6280"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bi-gram samples: [\"'cause can't\", \"'em better\", \"'expected errors'\", \"'karla' next\", \"'nodis' password\", \"'official doctrine\", \"'ok see\", \"'sci astro'\", \"'what's moonbase\", 'aas american']\n",
            "Train set score: 0.976\n",
            "Test set score: 0.773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(token_pattern=\"[a-zA-Z']{3,}\",\n",
        "                        decode_error='ignore',\n",
        "                        lowercase=True,\n",
        "                        stop_words=stopwords.words('english'),\n",
        "                        ngram_range=(1, 3),     # Tri-gram Settings\n",
        "                        max_df=.5,\n",
        "                        min_df=2)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "print(X_train_tfidf.shape)\n",
        "\n",
        "trigram_features = [f for f in tfidf.get_feature_names_out() if len(f.split()) > 2]\n",
        "print('tri-gram samples:', trigram_features[:10])\n",
        "\n",
        "ridge_clf.fit(X_train_tfidf, y_train)     # Train\n",
        "print('Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ-ePCY8kr9r",
        "outputId": "70d184be-0ba1-48a3-ac50-1f1e6eaf82a3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2034, 32943)\n",
            "tri-gram samples: [\"'em better shots\", \"'expected errors' basically\", \"'karla' next one\", \"'nodis' password also\", \"'official doctrine think\", \"'ok see warning\", \"'what's moonbase good\", 'aas american astronautical', 'ability means infallible', 'able accept donations']\n",
            "Train set score: 0.976\n",
            "Test set score: 0.775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classification of Korean Documents"
      ],
      "metadata": {
        "id": "qpQdDAPTm_eM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predict Movie Titles for the DAUM Movie Review"
      ],
      "metadata": {
        "id": "axYEGdLSnZL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/wikibook/textmining/main/data/daum_movie_review.csv')\n",
        "df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f6zI6dKfnheO",
        "outputId": "be223146-01ea-4018-8af2-952e2d6a638c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  rating        date  \\\n",
              "0                             돈 들인건 티가 나지만 보는 내내 하품만       1  2018.10.29   \n",
              "1       몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.      10  2018.10.26   \n",
              "2  이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...       8  2018.10.24   \n",
              "3                                이 정도면 볼만하다고 할 수 있음!       8  2018.10.22   \n",
              "4                                               재미있다      10  2018.10.20   \n",
              "\n",
              "    title  \n",
              "0  인피니티 워  \n",
              "1  인피니티 워  \n",
              "2  인피니티 워  \n",
              "3  인피니티 워  \n",
              "4  인피니티 워  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1a243f5-36e1-4d91-b693-bbbee2d5fa97\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>rating</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>돈 들인건 티가 나지만 보는 내내 하품만</td>\n",
              "      <td>1</td>\n",
              "      <td>2018.10.29</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>몰입할수밖에 없다. 어렵게 생각할 필요없다. 내가 전투에 참여한듯 손에 땀이남.</td>\n",
              "      <td>10</td>\n",
              "      <td>2018.10.26</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>이전 작품에 비해 더 화려하고 스케일도 커졌지만.... 전국 맛집의 음식들을 한데 ...</td>\n",
              "      <td>8</td>\n",
              "      <td>2018.10.24</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>이 정도면 볼만하다고 할 수 있음!</td>\n",
              "      <td>8</td>\n",
              "      <td>2018.10.22</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>재미있다</td>\n",
              "      <td>10</td>\n",
              "      <td>2018.10.20</td>\n",
              "      <td>인피니티 워</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1a243f5-36e1-4d91-b693-bbbee2d5fa97')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1a243f5-36e1-4d91-b693-bbbee2d5fa97 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1a243f5-36e1-4d91-b693-bbbee2d5fa97');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.title.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4zezLrzoObS",
        "outputId": "1e2bc320-0837-4507-ef01-847aa122427c"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "신과함께      4947\n",
              "택시운전사     2322\n",
              "인피니티 워    2042\n",
              "범죄도시      1939\n",
              "곤지암       1547\n",
              "라라랜드      1150\n",
              "코코         778\n",
              "Name: title, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Separation of data and labels into Train and Test sets\n",
        "# If No Ratio is Specified, it is split 75:25.\n",
        "X_train, X_test, y_train, y_test = train_test_split(df.review, df.title, random_state=0)\n",
        "\n",
        "print('# Train set size:', len(X_train))     # Check how many attributes are actually used\n",
        "print('# Test set size:', len(X_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZxGImSUoTiA",
        "outputId": "498411d4-55e7-440d-9b08-8de18b615d11"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set size: 11043\n",
            "# Test set size: 3682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9xmWKUVpK54",
        "outputId": "cc081c8e-574a-4243-899c-97e5a399dfdb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 951 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.9.1)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 42.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Okt\n",
        "okt = Okt()\n",
        "\n",
        "print(okt.morphs(X_train[1]))     # Tokenize morpheme-wise for the second review\n",
        "print(okt.nouns(X_train[1]))      # Extract only nouns from the second review"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWYu3095o6dO",
        "outputId": "b52fbf84-6f46-41e9-a861-874080afe8f6"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['몰입', '할수밖에', '없다', '.', '어렵게', '생각', '할', '필요없다', '.', '내', '가', '전투', '에', '참여', '한', '듯', '손', '에', '땀', '이남', '.']\n",
            "['몰입', '생각', '내', '전투', '참여', '듯', '손', '땀', '이남']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Using a function that extracts only nouns from the Twitter stemmer as a tokenizer\n",
        "tfidf = TfidfVectorizer(tokenizer=okt.nouns, max_features=2000, min_df=5, max_df=.5)\n",
        "\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)      # Convert train data -> tfidf vector\n",
        "X_test_tfidf = tfidf.transform(X_test)            # Convert test data -> tfidf vector\n",
        "\n",
        "# Logistic Regression Classifier Declaration\n",
        "# Set max_iter to 1,000 for sufficient training, default is 100\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)     # Train Classifier\n",
        "# Prediction Accuracy train data\n",
        "print('# Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
        "# Prediction Accuracy test data\n",
        "print('# Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUH0RMZ4pJ3G",
        "outputId": "46419e1f-8b29-4eef-f1bc-23a20ec78172"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.756\n",
            "# Test set score: 0.694\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('실제 영화 제목, 예측한 제목, 리뷰')\n",
        "for content in zip(y_test[:10], clf.predict(X_test_tfidf[:10]), X_test[:10]):\n",
        "  print(content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfeNyVUmqb-A",
        "outputId": "9e5b6adf-118c-4382-c67e-5ef56adb973a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "실제 영화 제목, 예측한 제목, 리뷰\n",
            "('범죄도시', '신과함께', '오랜만에 잼나는 영화 봤습니다.  다음에 더 재미있는 영화 기대하겠습니다.')\n",
            "('범죄도시', '범죄도시', '조연들이 눈에 박힌다. 간만에 집중 ㅎ')\n",
            "('코코', '코코', '대감동을 선사. 인사이드 아웃을 잇는 픽사의 감동스토리. 신과함께의 멕시코판이라고나할까요??')\n",
            "('신과함께', '신과함께', '돈이 안아까웠던 영화ᆞᆞ  정말 좋았다')\n",
            "('신과함께', '신과함께', '역시 김용화감독이 영화는 잘 만들어요. 이제 VFX 제작 부문도 헐리우드 수준 이상입니다.')\n",
            "('택시운전사', '택시운전사', '민주화를 위해 힘써주신 분들께 감사하는 마음으로 살아야겠다.')\n",
            "('신과함께', '신과함께', '잠만 자다 왔음')\n",
            "('신과함께', '신과함께', '오랜만에 잼있고 좋은 영화를 봤다')\n",
            "('범죄도시', '신과함께', '잼남')\n",
            "('범죄도시', '인피니티 워', '대박~~')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Efforts to Improve Performance"
      ],
      "metadata": {
        "id": "UPctFtLOqslY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use all morphemes instead of Nouns\n",
        "tfidf = TfidfVectorizer(tokenizer=okt.morphs, max_features=2000, min_df=5, max_df=.5)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "# Set max_iter to 1,000 for sufficient training, default is 100\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Prediction Accuracy train data\n",
        "print('# Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
        "# Prediction Accuracy test data\n",
        "print('# Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq7heHanq7QR",
        "outputId": "ae089386-9d97-43a9-f733-efa3e5b524f0"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.777\n",
            "# Test set score: 0.695\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def twit_tokenizer(text):     # Instead of using the whole, use nouns, verbs, and adjectives.\n",
        "  target_tags = ['Noun', 'Verb', 'Adjective']\n",
        "  result = []\n",
        "  for word, tag in okt.pos(text, norm=True, stem=True):\n",
        "    if tag in target_tags:\n",
        "      result.append(word)\n",
        "  return result\n",
        "\n",
        "# Create tfidf using nouns, verbs and adjectives\n",
        "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=.5)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('# Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
        "print('# Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW7Ak23BrisV",
        "outputId": "659bc25e-fb38-4e52-a827-bfac9a1f471f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.784\n",
            "# Test set score: 0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# What if I use all the morphemes and know the parts of speech?\n",
        "def twit_tokenizer2(text):\n",
        "  result = []\n",
        "  for word, tag in okt.pos(text, norm=True, stem=True):\n",
        "    result.append('/'.join([word, tag]))      # Able to Distinguish POS in words\n",
        "  return result\n",
        "\n",
        "print(twit_tokenizer2(X_train[1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_dshww-OsP_q",
        "outputId": "72fb1e8f-c6dc-4767-9549-2b0b0382bcb7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['몰입/Noun', '하다/Verb', '없다/Adjective', './Punctuation', '어렵다/Adjective', '생각/Noun', '하다/Verb', '필요없다/Adjective', './Punctuation', '내/Noun', '가/Josa', '전투/Noun', '에/Josa', '참여/Noun', '한/Determiner', '듯/Noun', '손/Noun', '에/Josa', '땀/Noun', '이남/Noun', './Punctuation']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf = TfidfVectorizer(tokenizer=twit_tokenizer, max_features=2000, min_df=5, max_df=.5)\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)\n",
        "\n",
        "clf = LogisticRegression(max_iter=1000)\n",
        "clf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('# Train set score: {:.3f}'.format(clf.score(X_train_tfidf, y_train)))\n",
        "print('# Test set score: {:.3f}'.format(clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Gi1xoIhsteG",
        "outputId": "46b714bd-582a-411f-9ced-a4297478bf15"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Train set score: 0.784\n",
            "# Test set score: 0.712\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_ridge, X_val_ridge, y_train_ridge, y_val_ridge = train_test_split(\n",
        "    X_train_tfidf, y_train, test_size=.2, random_state=42)\n",
        "\n",
        "max_score = 0\n",
        "max_alpha = 0\n",
        "for alpha in np.arange(0.1, 10, 0.1):     # Increase alpha by 0.1 from 0.1 to 10\n",
        "  ridge_clf = RidgeClassifier(alpha=alpha)      # Ridge Classifier Declaration\n",
        "  ridge_clf.fit(X_train_ridge, y_train_ridge)   # Train\n",
        "  # Measuring Accuracy on a Validate Dataset\n",
        "  score = ridge_clf.score(X_val_ridge, y_val_ridge)\n",
        "  if score > max_score:     # If the accuracy is greater than the previous accuracy maximum, change the maximum\n",
        "    max_score = score\n",
        "    max_alpha = alpha\n",
        "print('# Max alpha {:.3f} at max validation score {:.3f}'.format(max_alpha, max_score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMWp5kD5sxy1",
        "outputId": "5b1947bf-f168-49bb-ec76-7bb726616d7d"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Max alpha 2.500 at max validation score 0.719\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "ridge_clf = RidgeClassifier(alpha=1.6)\n",
        "ridge_clf.fit(X_train_tfidf, y_train)\n",
        "print('# Ridge Train set score: {:.3f}'.format(ridge_clf.score(X_train_tfidf, y_train)))\n",
        "print('# Ridge Test set score: {:.3f}'.format(ridge_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "lasso_clf = LogisticRegression(penalty='l1', solver='liblinear', C=0.5)\n",
        "lasso_clf.fit(X_train_tfidf, y_train)\n",
        "print('# Lasso Train set score: {:.3f}'.format(lasso_clf.score(X_train_tfidf, y_train)))\n",
        "print('# Lasso Test set score: {:.3f}'.format(lasso_clf.score(X_test_tfidf, y_test)))\n",
        "\n",
        "print(\n",
        "    '# Used features count: {}'.format(np.sum(lasso_clf.coef_ != 0)),\n",
        "    'out of',\n",
        "    X_train_tfidf.shape[1]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hf268FxVtvx8",
        "outputId": "5357e160-2207-42d6-dc5f-9b1d258553b0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Ridge Train set score: 0.797\n",
            "# Ridge Test set score: 0.715\n",
            "# Lasso Train set score: 0.700\n",
            "# Lasso Test set score: 0.695\n",
            "# Used features count: 951 out of 2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "NB_clf = MultinomialNB(alpha=0.1)\n",
        "NB_clf.fit(X_train_tfidf, y_train)\n",
        "print('Train set score: {:.3f}'.format(NB_clf.score(X_train_tfidf, y_train)))\n",
        "print('Test set score: {:.3f}'.format(NB_clf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hstQV2HxuZAt",
        "outputId": "55c99f2e-5611-4a98-f491-6752e9554194"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set score: 0.773\n",
            "Test set score: 0.710\n"
          ]
        }
      ]
    }
  ]
}